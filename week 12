This week, I used AI as a learning tool while working through the exercises to help explain certain Python concepts and provide simple coding examples, such as how f-strings work. I did not use AI to complete any of the exercises themselves, and I also did not rely on AI for debugging my code. Here is a link to my AI chat for reference: https://chatgpt.com/share/68bdbf24-0104-8010-a4f3-e3077a4692cd
My project team also used AI to help organize our initial project ideas and translate them into clearer project requirements, which we then used to draft our project charter. [link to chat]
I also experimented with Gemini AI this week and did not have a great experience using it. I found its responses to be less clear and less aligned with what I was looking for compared to other tools, which made it harder to apply to my work.
To explore this further, I ran a comparison test using the same documents and prompts across Claude, ChatGPT, and Gemini. Even with identical prompts, each tool produced noticeably different results. I used a separate instance of Claude to help design, analyze, and refine the test itself. Ultimately, we optimized both the prompt and documents for ChatGPT, which gave results that were closest to our expected outcomes. This process helped me understand how different AI models can produce very different outputs due to variations in how they process information, similar to how people bring different perspectives and biases into analysis.
